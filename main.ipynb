{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-04T23:10:45.500999Z",
     "start_time": "2023-11-04T23:10:45.464064Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import speech_recognition as sr\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925bc119",
   "metadata": {},
   "source": [
    "Read API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b61bb633f391b91a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T23:10:45.505289Z",
     "start_time": "2023-11-04T23:10:45.467757Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('openai_key.txt') as f:\n",
    "    openai.api_key = f.read()\n",
    "\n",
    "with open('google_key.txt') as f:\n",
    "    GOOGLE_SPEECH_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "STARTING_PROMPT = 'What would you like to talk about today?'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T23:10:45.505933Z",
     "start_time": "2023-11-04T23:10:45.474877Z"
    }
   },
   "id": "d93f5734c77f9b63"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98fee9db98b16e05",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T23:10:52.240296Z",
     "start_time": "2023-11-04T23:10:45.489494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "\n",
    "m = sr.Microphone()\n",
    "with m as source:\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    print(\"Say something!\")\n",
    "    \n",
    "    audio = r.listen(source)\n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "try:\n",
    "    # for testing purposes, we're just using the default API key\n",
    "    # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
    "    # instead of `r.recognize_google(audio)`\n",
    "    user_speech = r.recognize_google(audio)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T23:10:54.308947Z",
     "start_time": "2023-11-04T23:10:52.238123Z"
    }
   },
   "id": "69a71ca94b7277e0"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "user_speech = \"I want to talk about the weather\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T23:27:41.847808Z",
     "start_time": "2023-11-04T23:27:41.842501Z"
    }
   },
   "id": "f7f477db8065dbd7"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! Weather is always a good topic of conversation. How has the weather been in your area recently?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an English tutor holding a conversation with a student.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hello, what do you want to talk about?\"},\n",
    "    {\"role\": \"user\", \"content\": user_speech},\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message['content'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T23:29:27.741572Z",
     "start_time": "2023-11-04T23:29:25.573616Z"
    }
   },
   "id": "93ad502e16c1dcab"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# Initialize recognizer and microphone\n",
    "r = sr.Recognizer()\n",
    "m = sr.Microphone()\n",
    "\n",
    "# Starting messages for the conversation\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an English tutor holding a conversation with a student.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hello, what do you want to talk about?\"}\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T23:36:41.290805Z",
     "start_time": "2023-11-04T23:36:41.262561Z"
    }
   },
   "id": "6e06b142228439a6"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello, what do you want to talk about?\n",
      "You: (Speak now!)\n",
      "Assistant: Hi there! That's a great topic to talk about. So, how's the weather been in your area lately?\n",
      "You: (Speak now!)\n",
      "Assistant: Oh, interesting! Is it a warm or cool breeze? And has it been consistent or does it come and go throughout the day?\n",
      "You: (Speak now!)\n",
      "Assistant: Ah, it sounds like there might have been a change in weather patterns. Those sudden shifts can be quite surprising, right? So, when it was warm yesterday, did it feel more like a spring day or did it just briefly transition to warmer temperatures?\n",
      "You: (Speak now!)\n",
      "Sorry, I couldn't understand that. Please try again.\n",
      "You: (Speak now!)\n",
      "Sorry, I couldn't understand that. Please try again.\n",
      "You: (Speak now!)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[64], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m     r\u001B[38;5;241m.\u001B[39madjust_for_ambient_noise(source)\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou: (Speak now!)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 9\u001B[0m     audio \u001B[38;5;241m=\u001B[39m \u001B[43mr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlisten\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Convert speech to text\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/Programming/PycharmProjects/convo-partner/venv/lib/python3.9/site-packages/speech_recognition/__init__.py:523\u001B[0m, in \u001B[0;36mRecognizer.listen\u001B[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001B[0m\n\u001B[1;32m    520\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m phrase_time_limit \u001B[38;5;129;01mand\u001B[39;00m elapsed_time \u001B[38;5;241m-\u001B[39m phrase_start_time \u001B[38;5;241m>\u001B[39m phrase_time_limit:\n\u001B[1;32m    521\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m--> 523\u001B[0m buffer \u001B[38;5;241m=\u001B[39m \u001B[43msource\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCHUNK\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(buffer) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m: \u001B[38;5;28;01mbreak\u001B[39;00m  \u001B[38;5;66;03m# reached end of the stream\u001B[39;00m\n\u001B[1;32m    525\u001B[0m frames\u001B[38;5;241m.\u001B[39mappend(buffer)\n",
      "File \u001B[0;32m~/Documents/Programming/PycharmProjects/convo-partner/venv/lib/python3.9/site-packages/speech_recognition/__init__.py:199\u001B[0m, in \u001B[0;36mMicrophone.MicrophoneStream.read\u001B[0;34m(self, size)\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread\u001B[39m(\u001B[38;5;28mself\u001B[39m, size):\n\u001B[0;32m--> 199\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpyaudio_stream\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexception_on_overflow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Programming/PycharmProjects/convo-partner/venv/lib/python3.9/site-packages/pyaudio/__init__.py:570\u001B[0m, in \u001B[0;36mPyAudio.Stream.read\u001B[0;34m(self, num_frames, exception_on_overflow)\u001B[0m\n\u001B[1;32m    567\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_input:\n\u001B[1;32m    568\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNot input stream\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    569\u001B[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001B[0;32m--> 570\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpa\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_frames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    571\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mexception_on_overflow\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Assistant: Hello, what do you want to talk about?\")\n",
    "\n",
    "# Conversation loop\n",
    "while True:\n",
    "    # Listen to user's speech\n",
    "    with m as source:\n",
    "        r.adjust_for_ambient_noise(source)\n",
    "        print(\"You: (Speak now!)\")\n",
    "        audio = r.listen(source)\n",
    "\n",
    "    # Convert speech to text\n",
    "    try:\n",
    "        user_speech = r.recognize_google(audio)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I couldn't understand that. Please try again.\")\n",
    "        continue\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "        break\n",
    "    \n",
    "    # Check if user wants to end the conversation\n",
    "    if user_speech.lower() in [\"exit\", \"end\", \"stop\", \"quit\"]:\n",
    "        print(\"Ending conversation. Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Add user's message to the conversation\n",
    "    messages.append({\"role\": \"user\", \"content\": user_speech})\n",
    "\n",
    "    # Get a response from OpenAI API\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    assistant_response = response.choices[0].message['content']\n",
    "    print(f\"Assistant: {assistant_response}\")\n",
    "    messages.append({\"role\": \"assistant\", \"content\": assistant_response})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T23:38:00.010177Z",
     "start_time": "2023-11-04T23:37:08.953237Z"
    }
   },
   "id": "9600c7ede3bc93a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1cb624b1608541ac"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
